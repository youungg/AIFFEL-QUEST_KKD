{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c886ed9",
   "metadata": {},
   "source": [
    "### ğŸš© Import libraries & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23607152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# import visual tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "\n",
    "# import util tools\n",
    "import os\n",
    "from os.path import join    # define route of files\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# import data pre-processing tools\n",
    "import missingno as msno    # check missing data\n",
    "\n",
    "\n",
    "# import ML tools 1\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "# import ML tools 2\n",
    "import sklearn.ensemble as ensemble\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "    # XGBM (extreme GBM), LGBM (lighting GBM) :\n",
    "    # gradient boosting machine (GBM) ì•Œê³ ë¦¬ì¦˜ ê³„ì—´ì˜ ë³€í˜•\n",
    "    # ê°ê° ë…ìì ì¸ ì˜¤í”ˆ ì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜•íƒœë¡œ í•´ë‹¹ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0995f3c",
   "metadata": {},
   "source": [
    "### ğŸš© Define constants (hyper params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9081599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2020\n",
    "\n",
    "TEST_SIZE = 0.2    # train/test split ratio for train_test_split()\n",
    "CV_SIZE = 5        # cross validation size\n",
    "\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad311fc",
   "metadata": {},
   "source": [
    "### ğŸš© Load data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f4e4de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define routes of data(.csv) files\n",
    "data_dir = \"~/aiffel/kaggle_kakr_housing/data/\"\n",
    "\n",
    "\n",
    "# load csv files -> pd.DataFrame\n",
    "train_data = pd.read_csv(join(data_dir, \"train.csv\"))\n",
    "test_data = pd.read_csv(join(data_dir, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20be0f9",
   "metadata": {},
   "source": [
    "### ğŸš© Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78630dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train data pre-processing\n",
    "\n",
    "# \"date\" column format change\n",
    "train_data[\"date\"] = train_data[\"date\"].apply(lambda i: i[:6]).astype(int)\n",
    "\n",
    "# \"price\" column regularization(?) -> grow variation of \"price\" values\n",
    "train_data[\"price\"] = np.log1p(train_data[\"price\"])\n",
    "\n",
    "# \"id\" column remove\n",
    "train_data = train_data.drop(columns = [\"id\"])\n",
    "\n",
    "\n",
    "\n",
    "### test data pre-processing\n",
    "\n",
    "# \"date\" column format change\n",
    "test_data[\"date\"] = test_data[\"date\"].apply(lambda i: i[:6]).astype(int)\n",
    "\n",
    "# \"id\" column remove\n",
    "test_data = test_data.drop(columns = [\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c674f9fc",
   "metadata": {},
   "source": [
    "### ğŸš© Extract feature matrices (X) & target vectors (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "557c9f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train data -> feature matrix (X) & target vector (y) split\n",
    "X = train_data.drop(columns = [\"price\"])    # exclude target vector column\n",
    "y = train_data[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad143dd",
   "metadata": {},
   "source": [
    "### ğŸš© Define useful methods (RMSE, cross validation, grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c4dff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get RMSE losses from log(\"price\") values\n",
    "def getRMSE_log2exp(y_test, y_pred):\n",
    "    y_test, y_pred = np.expm1(y_test), np.expm1(y_pred)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "\n",
    "# get cross validation scores of \"one\" learning model (for model evaluation)\n",
    "def getCVscore(X, model):\n",
    "    kfold = model_selection.KFold(n_splits = CV_SIZE).get_n_splits(X.values)\n",
    "    score = np.mean(model_selection.cross_val_score(model, X = X.values, y = y, cv = kfold))\n",
    "    print(\"CV score of\", model.__class__.__name__, \":\", score)\n",
    "    return score\n",
    "        \n",
    "    \n",
    "    \n",
    "# search best parameter values for learning models\n",
    "def searchBestParams(model, X, y, param_grid, verbose = 2, n_jobs = 5):\n",
    "    # initialize grid search model\n",
    "    grid = model_selection.GridSearchCV(model, param_grid = param_grid, \\\n",
    "                                        scoring = \"neg_mean_squared_error\", \\\n",
    "                                        cv = CV_SIZE, verbose = verbose, n_jobs = n_jobs)\n",
    "    \n",
    "    # grid search model fitting\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    # return best 5 parameter values\n",
    "    result = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "    result[\"score\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "    result = result.sort_values(\"score\", ascending = False, ignore_index = True)\n",
    "    print(result.head())\n",
    "    return result.head()\n",
    "\n",
    "\n",
    "\n",
    "# save predicted \"price\" values as a submission file\n",
    "def makeSubmissionFile(y_pred):\n",
    "    data_dir = \"~/aiffel/kaggle_kakr_housing/data/\"\n",
    "    submission = pd.read_csv(join(data_dir, \"sample_submission.csv\"))\n",
    "    submission[\"price\"] = y_pred\n",
    "    submission.to_csv(join(data_dir, \"submission_new.csv\"), index = False)\n",
    "    print(\"The submission file has created succesfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480221a5",
   "metadata": {},
   "source": [
    "### ğŸš© Generate & evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01c9d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model instances\n",
    "extreme = xgb.XGBRegressor(random_state = RANDOM_STATE)\n",
    "light = lgb.LGBMRegressor(random_state = RANDOM_STATE)\n",
    "boost = ensemble.GradientBoostingRegressor(random_state = RANDOM_STATE)\n",
    "forest = ensemble.RandomForestRegressor(random_state = RANDOM_STATE)\n",
    "\n",
    "# create my own learning model collections\n",
    "models = [extreme, light, boost, forest]\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate model performance (cross validation)\n",
    "#for model in models:\n",
    "#    score = getCVscore(X, model)\n",
    "\n",
    "# Output :\n",
    "# CV score of XGBRegressor  :  0.8973388661281285\n",
    "# CV score of LGBMRegressor  :  0.9024911910917768\n",
    "# CV score of GradientBoostingRegressor  :  0.8796312932769542\n",
    "# CV score of RandomForestRegressor : 0.8851571351312119\n",
    "\n",
    "### It seems four models provide sufficiently high performance!\n",
    "### cross validation ì‹¤í–‰ ê²°ê³¼, 4ê°œì˜ í•™ìŠµ ëª¨ë¸ì´ ì¶©ë¶„í•œ ì„±ëŠ¥ì„ ì œê³µí•œë‹¤ëŠ” ê²ƒì„ í™•ì¸\n",
    "### ê·¸ë ‡ë‹¤ë©´ í•´ë‹¹ 4ê°œì˜ í•™ìŠµ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ í•™ìŠµ & ì˜ˆì¸¡ ë„ì „!!\n",
    "### ì„±ëŠ¥ í™•ì¸ì„ ë§ˆì³¤ìœ¼ë¯€ë¡œ, ì„±ëŠ¥ í‰ê°€ ê³¼ì •ì€ ì£¼ì„(#)ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ë‹¤ìŒ ì½”ë“œ ì‹¤í–‰ ë•ŒëŠ” ìƒëµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb236fc8",
   "metadata": {},
   "source": [
    "### ğŸš© Search best LGBM param values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76f6b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set available values for LGBM parameters\n",
    "lgbm_param_grid = {\"max_depth\" : [-1], \\\n",
    "                    \"learning_rate\" : [0.01, 0.05, 0.1], \\\n",
    "                    \"n_estimators\" : [50, 75, 100], \\\n",
    "                    \"num_leaves\" : [26, 31, 36], \\\n",
    "                    \"boosting_type\" : [\"gbdt\"], \\\n",
    "                    \"reg_lambda\" : [30, 50, 70]}\n",
    "    # max_depth : ì˜ì‚¬ ê²°ì • ë‚˜ë¬´ì˜ ê¹Šì´, ì •ìˆ˜ ì‚¬ìš©\n",
    "    # learning_rate : í•œ ìŠ¤í…ì— ì´ë™í•˜ëŠ” ì–‘ì„ ê²°ì •í•˜ëŠ” íŒŒë¼ë¯¸í„°, ë³´í†µ 0.0001~0.1 ì‚¬ì´ì˜ ì‹¤ìˆ˜ ì‚¬ìš©\n",
    "    # n_estimators : ì‚¬ìš©í•˜ëŠ” ê°œë³„ ëª¨ë¸ì˜ ê°œìˆ˜, ë³´í†µ 50~100 ì´ìƒì˜ ì •ìˆ˜ ì‚¬ìš©\n",
    "    # num_leaves : í•˜ë‚˜ì˜ LightGBM íŠ¸ë¦¬ê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ìµœëŒ€ ìì˜ ìˆ˜\n",
    "    # boosting_type : ë¶€ìŠ¤íŒ… ë°©ì‹, gbdt, rf ë“±ì˜ ë¬¸ìì—´ ì…ë ¥\n",
    "    # reg_lambda : L2 regularization term on weights\n",
    "\n",
    "    \n",
    "# Search best set of parameter values\n",
    "#print(searchBestParams(light, X, y, lgbm_param_grid, verbose = 0))\n",
    "\n",
    "# Output :\n",
    "#   boosting_type  learning_rate  max_depth  n_estimators  num_leaves  reg_lambda      score\n",
    "# 0          gbdt            0.1         -1           100          36          30  -0.026989\n",
    "# 1          gbdt            0.1         -1           100          31          30  -0.027051\n",
    "# 2          gbdt            0.1         -1           100          36          50  -0.027284\n",
    "# 3          gbdt            0.1         -1           100          26          30  -0.027552\n",
    "# 4          gbdt            0.1         -1           100          31          50  -0.027646\n",
    "\n",
    "### LGBMëŠ” learning_rate = 0.1, n_estimators = 100, num_leaves = 36, reg_lambda = 30 ì¼ ë•Œ ìµœìƒì˜ ì„±ëŠ¥ì„ì„ í™•ì¸\n",
    "### XGBM ë˜í•œ LGBMê³¼ ìœ ì‚¬í•œ GBM ê³„ì—´ì˜ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì´ë¯€ë¡œ, ìœ ì‚¬í•œ ìˆ˜ì¹˜ ëŒ€ì…í•˜ë©´ OK\n",
    "### íŒŒë¼ë¯¸í„° ê°’ë³„ ì„±ëŠ¥ í™•ì¸ì„ ë§ˆì³¤ìœ¼ë¯€ë¡œ, íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³¼ì •ì€ ì£¼ì„(#)ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ë‹¤ìŒ ì½”ë“œ ì‹¤í–‰ ë•ŒëŠ” ìƒëµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb60b42",
   "metadata": {},
   "source": [
    "### ğŸš© Adjust XGBD & LGBD params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9125202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate another model instances with adjusted params\n",
    "extreme = xgb.XGBRegressor(random_state = RANDOM_STATE, learning_rate = 0.2, n_estimators = 100)\n",
    "light = lgb.LGBMRegressor(random_state = RANDOM_STATE, learning_rate = 0.1, n_estimators = 300, num_leaves = 36, reg_lambda = 30)\n",
    "\n",
    "# Update XGBD & LGBD models in my model collection\n",
    "models[0] = extreme\n",
    "models[1] = light\n",
    "\n",
    "### grid search ê²°ê³¼ ê°’ê³¼ ìœ ì‚¬í•œ ê°’ ìœ„ì£¼ë¡œ ë‹¤ì–‘í•œ ê°’ì„ ì‹œë„í•´ ë³¸ ê²°ê³¼, í•´ë‹¹ íŒŒë¼ë¯¸í„° ê°’ìœ¼ë¡œ ê²°ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5906f400",
   "metadata": {},
   "source": [
    "### ğŸš© Perform fit() & predict() -> Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6b51e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of XGBRegressor  :  107509.3104391456\n",
      "RMSE of LGBMRegressor  :  104654.07159199048\n",
      "RMSE of GradientBoostingRegressor  :  128360.19649691365\n",
      "RMSE of RandomForestRegressor  :  125487.07102453562\n"
     ]
    }
   ],
   "source": [
    "for model in models :\n",
    "    # split train data -> for training & for valication\n",
    "    X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, \\\n",
    "                                        test_size = TEST_SIZE, random_state = RANDOM_STATE)\n",
    "\n",
    "    # model fitting (learning)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict \"price\"\n",
    "    y_pred = model.predict(X_valid)\n",
    "\n",
    "    # get error (wish less than 1.1M)\n",
    "    error = getRMSE_log2exp(y_valid, y_pred)\n",
    "    print(\"RMSE of\", model.__class__.__name__, \" : \", error)\n",
    "    \n",
    "# Output :\n",
    "# RMSE of XGBRegressor  :  107509.3104391456\n",
    "# RMSE of LGBMRegressor  :  104654.07159199048\n",
    "# RMSE of GradientBoostingRegressor  :  128360.19649691365\n",
    "# RMSE of RandomForestRegressor  :  125487.07102453562\n",
    "\n",
    "### XGBM, LGBM ëª¨ë¸ì´ í¬ë§ì´ ë³´ì´ë¯€ë¡œ ë‘ ê°€ì§€ ëª¨ë¸ì— ëŒ€í•˜ì—¬ ensemble ê¸°ë²•ì„ ì‹œë„í•´ë³´ì"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e24ebf",
   "metadata": {},
   "source": [
    "### ğŸš© Define ensemble system methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fbf348e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create XGBM/LGBM models with random seed and fitting for EPOCHS iteration\n",
    "def getAveragingBlending(X, y, X_test, epochs, XGBM = False, LGBM = False):\n",
    "    y_preds = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        if XGBM:    # XGBM model\n",
    "            model = xgb.XGBRegressor(learning_rate = 0.2, n_estimators = 100)\n",
    "        else:      # LGBM model\n",
    "            model = lgb.LGBMRegressor(learning_rate = 0.1, n_estimators = 300, num_leaves = 36, reg_lambda = 30)\n",
    "            \n",
    "        X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size = TEST_SIZE)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_preds.append(y_pred)  # save predicted values from each model\n",
    "\n",
    "    y_preds = np.array(y_preds) \n",
    "    mean = np.mean(y_preds, axis = 0)    # get mean values of predicted values\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bdb7ed",
   "metadata": {},
   "source": [
    "### ğŸš© Predict \"price\" with various learning ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27205a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. predict with only one XGBM\n",
    "#extreme = xgb.XGBRegressor(random_state = RANDOM_STATE, learning_rate = 0.2, n_estimators = 100)\n",
    "#extreme.fit(X, y)\n",
    "#y_pred = extreme.predict(test_data)\n",
    "\n",
    "\n",
    "# 2-1. predict with only one LGBM\n",
    "#light = lgb.LGBMRegressor(random_state = RANDOM_STATE, learning_rate = 0.1, n_estimators = 300, num_leaves = 36)\n",
    "#light.fit(X, y)\n",
    "#y_pred = light.predict(test_data)\n",
    "\n",
    "\n",
    "# 2-2. predict with only one LGBM & regularization parameter 30\n",
    "#light_reg = lgb.LGBMRegressor(random_state = RANDOM_STATE, learning_rate = 0.1, n_estimators = 300, num_leaves = 36, reg_lambda = 30)\n",
    "#light_reg.fit(X, y)\n",
    "#y_pred = light_reg.predict(test_data)\n",
    "\n",
    "\n",
    "# 2-3. predict with only one LGBM & regularization parameter 50\n",
    "light_reg = lgb.LGBMRegressor(random_state = RANDOM_STATE, learning_rate = 0.1, n_estimators = 300, num_leaves = 36, reg_lambda = 50)\n",
    "light_reg.fit(X, y)\n",
    "y_pred = light_reg.predict(test_data)\n",
    "\n",
    "\n",
    "# 3. predict with ensembled XGBMs\n",
    "#y_pred = getAveragingBlending(X, y, test_data, EPOCHS, XGBM = True)\n",
    "\n",
    "\n",
    "# 4. predict with ensembled LGBMs\n",
    "#y_pred = getAveragingBlending(X_train, y_train, X_valid, EPOCHS, LGBM = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc751c",
   "metadata": {},
   "source": [
    "### ğŸš© Save predicted \"price\" as submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93c3aa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The submission file has created succesfully.\n"
     ]
    }
   ],
   "source": [
    "# recover original price value range\n",
    "y_pred = np.expm1(y_pred)\n",
    "\n",
    "# save as file\n",
    "makeSubmissionFile(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2479bcee",
   "metadata": {},
   "source": [
    "-----\n",
    "**íšŒê³ ë¡** :  \n",
    "XGBM, LGBM ì´ ë‹¤ë¥¸ í•™ìŠµ ëª¨ë¸ì— ë¹„í•´ ì„±ëŠ¥ì´ ì¢‹ë‹¤ë˜ë°, ëª¸ì†Œ ì²´í—˜í•  ìˆ˜ ìˆì—ˆë‹¤  \n",
    "ë˜í•œ ê°™ì€ ëª¨ë¸ì´ë¼ë„ parameter ê°’ì— ë”°ë¼ì„œë„ ì¶©ë¶„íˆ ì„±ëŠ¥ì„ ì¡°ì •í•  ìˆ˜ ìˆìŒì„ ì²´ê°í–ˆë‹¤  \n",
    "ë™ì¼í•œ ëª¨ë¸ì— ì„œë¡œ ë‹¤ë¥¸ random seedë¥¼ ë¶€ì—¬í•´ì„œ ensemble ì„ ì‹œë„í•˜ì˜€ëŠ”ë°, ëŒ€ë¶€ë¶„ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì•˜ë‹¤\n",
    "ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì„ ë¬¶ì–´ì„œ ensemble ì„ í•´ì•¼ ì„±ëŠ¥ì´ í–¥ìƒë˜ëŠ”ê±¸ê¹Œ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f1fab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
